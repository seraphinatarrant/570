'''
A script that takes annotated training data and creates a state-emission HMM for a bigram POS tagger,
where output symbols are generated by the to-states. No smoothing.

Training data in format "word1/tag1....wordn/tagn" with one sentence per line, Output has standard HMM format.
Command to run: cat training_data | create_2gram_hmm.py output_hmm_file
(Yes it is weird to use cat, it was a requirement for some reason)

States: POS tags, BOS, EOS
Output symbols: words, <s>, </s> (the BOS and EOS symbols)
Init Prob: BOS 1.0
Transition prob: a_ij = P(s_j|s_i)
Emission prob: b_jk = P(w_k|s_j)

Where s is states and w is words.
So prob transition between from_state and to_state, and prob emit word given the to_state

Therefore:
Transition probabilities will be the bigram POS tag probabilities P(tag_i|tag_i-1)
Emission probabilities will be likelihood of the word given tag_i


'''

import sys
from collections import Counter, defaultdict

import re

import math


def process_sentence(input, regex):
    '''
    Read in sentences (batch or line by line)
    Insert BOS and EOS symbols and tags at sentence boundaries, split on whitespace, convert to word, tag tuples
    :param input: a sentence string
    :return: list of tuples of (word, tag) from processed sentence
    '''
    sentence_tuples = [('<s>', 'BOS')]
    #sentence = input.strip().split()
    sentence_tuples.extend([tuple(regex.split(token, 1)) for token in input.strip().split()])
    sentence_tuples.append(('<\/s>', 'EOS'))
    return sentence_tuples

def count_ngrams(input, n=2):
    '''
    Collects ngrams from input (splodged together from a more general ngram counter, hence why there is an n param)
    NOTE that I reverse the word_tag_bigram tuples to be tag_word bigram tuples for easier handling
    :param input: a list of sentence-lists of (word, tag) tuples
    :param n: the n of 'ngram' (eg unigram, bigram). Default  2. Wouldn't actually work with anything else at present.
    :return: counters of tag unigram, word unigram, tag word bigram,  and tag bigram
    '''
    tag_unigrams, tag_bigrams, word_unigrams, tag_word_bigrams = Counter(), Counter(), Counter(), Counter()
    for sentence in input:
        index, end = 0, len(sentence)
        #add ngrams to counter
        while index < end:
            tag_word_bigram = tuple(reversed(sentence[index])) #this is so the format is tag,word so I can treat it like a normal bigram probability
            tag_unigram, word_unigram = tag_word_bigram[0], tag_word_bigram[1]

            tag_unigrams[tag_unigram] += 1
            word_unigrams[word_unigram] += 1
            tag_word_bigrams[tag_word_bigram] += 1
            if index+(n-1) < end:
                tag_bigram = (tag_unigram, sentence[index + 1][1])
                tag_bigrams[tag_bigram] += 1
            index += 1 #steps forward in list
    return tag_unigrams, tag_bigrams, word_unigrams, tag_word_bigrams

def calc_bigram_probs(bigrams, unigrams):
    '''
    :param bigrams: a Counter of bigram tuples
    :param unigrams: a Counter of unigram strings
    :return: a defaultdict of bigram probabilities
    '''
    prob_dict = defaultdict(float)
    for key in bigrams:
        prob = bigrams[key]/unigrams[key[0]]
        log_prob = math.log10(prob)
        prob_dict[key] = (prob, log_prob)
    return prob_dict

def make_hmm(data, output_file='tmp_hmm'):
    #assume data is preprocessed
    tag_unigrams, tag_bigrams, word_unigrams, tag_word_bigrams = count_ngrams(data)
    state_num, sym_num = len(tag_unigrams), len(word_unigrams)

    #calc emission and tranition probs from unigram and bigram counters
    transitions = calc_bigram_probs(tag_bigrams, tag_unigrams)
    emissions = calc_bigram_probs(tag_word_bigrams, tag_unigrams)
    init_line_num, trans_line_num, emiss_line_num = 1, len(transitions), len(emissions)

    #format data
    init_lines = "BOS 1.0 {}".format(math.log10(1))
    transition_lines = ['{} {} {} {}'.format(bigram_prob[0][0], bigram_prob[0][1], bigram_prob[1][0],
                                             bigram_prob[1][1]) for bigram_prob in transitions.items()]
    emission_lines = ['{} {} {} {}'.format(bigram_prob[0][0], bigram_prob[0][1], bigram_prob[1][0],
                                             bigram_prob[1][1]) for bigram_prob in emissions.items()]

    output = ("state_num={}\n"
              "sym_num={}\n"
              "init_line_num={}\n"
              "trans_line_num={}\n"
              "emiss_line_num={}\n\n"
              "\\init\n"
              "{init_lines}\n\n\n\n"
              "\\transition\n"
              "{transition_lines}\n\n"
              "\\emission\n"
              "{emission_lines}\n").format(state_num, sym_num, init_line_num, trans_line_num, emiss_line_num,
                                           init_lines=init_lines, transition_lines='\n'.join(transition_lines),
                                           emission_lines='\n'.join(emission_lines))
    with open(output_file,'w') as outfile:
        outfile.write(output)



if __name__ == "__main__":
    #output_filename = sys.argv[1]
    input = sys.argv[1]
    #input = sys.stdin.readlines() #this is how it will actually be executed
    inputlines = []
    regex_obj = re.compile(r'(?<!=\\)/')
    with open(input, 'rU') as infile:
        for line in infile:
            inputlines.append(process_sentence(line, regex_obj))

    make_hmm(inputlines)
